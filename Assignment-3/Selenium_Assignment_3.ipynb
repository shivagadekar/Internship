{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a030e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException , NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e9e3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559aad83",
   "metadata": {},
   "source": [
    "# Q1 - Write a python program which searches all the product under a particular product from www.amazon.in. \n",
    "The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21066956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = webdriver.Chrome('C:/chrome_driver/chromedriver.exe')\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c832b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = driver.find_element(By.ID, \"twotabsearchtextbox\")  # Finding element with the help ID\n",
    "user_input = input('Enter Your Search = ')\n",
    "product.send_keys(user_input)  # Passing user_input as an search keyword\n",
    "product.send_keys(Keys.RETURN)  # Pressing enter to load results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17d07e",
   "metadata": {},
   "source": [
    "# Q2 - In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv.\n",
    "In case if any product has less than 3 pages in search results then scrape all the products available under that product name. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6caa56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Save Data\n",
    "name = []\n",
    "description = []\n",
    "price = []\n",
    "delivery_date = []\n",
    "item_links = []\n",
    "\n",
    "try:\n",
    "    driver = webdriver.Chrome('C:/chrome_driver/chromedriver.exe')  # Loading Chrome Driver\n",
    "    driver.get('https://www.amazon.in/')  # opening web address in chrome driver browser\n",
    "    \n",
    "    product = driver.find_element(By.ID, \"twotabsearchtextbox\")  # Finding element with the help ID\n",
    "    product.send_keys('Laptop')  # Passing \"Laptop\" as an search keyword\n",
    "    product.send_keys(Keys.RETURN)  # Pressing enter to load results\n",
    "    \n",
    "    # --------------------------- Scope to Apply Loop ----------------\n",
    "    all_rows = driver.find_elements(By.XPATH, '//div[@class=\"a-section\"]')\n",
    "    \n",
    "    \n",
    "    for k in all_rows:\n",
    "    \n",
    "        all_results = k.find_elements(By.XPATH, '//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "        for result in all_results:  # Looping for first 10 lapotps\n",
    "            i = result.text\n",
    "            b = i.split(' ')[0]\n",
    "            name.append(i.split(' ')[0])\n",
    "            print(b)\n",
    "            print(i[len(b)+1:])\n",
    "            description.append(i[len(b)+1:])\n",
    "            print('---------------------------------------------------------------------------------------------------')\n",
    "        \n",
    "        # finding elements with price information and extracting prices\n",
    "        price_element = k.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "        for _ in price_element:\n",
    "            i = _.text\n",
    "            price.append(i)\n",
    "            print(i)\n",
    "            \n",
    "            \n",
    "        # Finding Expected Delivert\n",
    "        Exp_delivery_date = k.find_elements(By.XPATH, '//span[@class=\"a-color-base a-text-bold\"]')\n",
    "        for _ in Exp_delivery_date:\n",
    "            i = _.text\n",
    "            delivery_date.append(i)\n",
    "            print(i)\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Finding Expected Delivert\n",
    "        item_link = k.find_elements(By.XPATH, '//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "        for _ in item_link:\n",
    "            i = _.get_attribute('href')\n",
    "            print(i)\n",
    "            item_links.append(i)\n",
    "        try:\n",
    "            next_page = driver.find_element(By.XPATH, '//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "            next_page.click()\n",
    "            time.sleep(5)\n",
    "            count += 1\n",
    "            if count == 3:\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            print('No Such Element')\n",
    "            break\n",
    "except NoSuchElementException:\n",
    "    print('No Such Element Exception')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9c5f4",
   "metadata": {},
   "source": [
    "# Q3 Write a python program to access the search bar and search button on images.google.com.\n",
    "scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ee75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\", chrome_options=options)\n",
    "driver.get('https://images.google.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = driver.find_element(By.XPATH, '//input[@class=\"gLFyf gsfi\"]')\n",
    "se = 'fruits'\n",
    "bar.send_keys(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/form/div[1]/div[1]/div[2]/div[2]/div[2]/ul[1]/div/ul/li[1]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6351dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=[]\n",
    "for i in driver.find_elements(By.XPATH, '//img[@class=\"rg_i Q4LuWd\"]'):\n",
    "    url.append(i.get_attribute('src'))\n",
    "\n",
    "url=url[:9]\n",
    "for i in url:\n",
    "    driver.get(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f74ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_searches = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n",
    "for i in list_of_searches:\n",
    "    driver = webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\", chrome_options=options)\n",
    "    driver.get('https://images.google.com/')\n",
    "    bar = driver.find_element(By.XPATH, '//input[@class=\"gLFyf gsfi\"]')\n",
    "    bar.send_keys(i)\n",
    "    search=driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/form/div[1]/div[1]/div[2]/div[2]/div[2]/ul[1]/div/ul/li[1]')\n",
    "    search.click()\n",
    "    url=[]\n",
    "    for i in driver.find_elements(By.XPATH, '//img[@class=\"rg_i Q4LuWd\"]'):\n",
    "        url.append(i.get_attribute('src'))\n",
    "\n",
    "    url=url[:9]\n",
    "    for i in url:\n",
    "        driver.get(i)\n",
    "        \n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd7cb2",
   "metadata": {},
   "source": [
    "# Q4 - Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. \n",
    "Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = selenium.webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\")\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "# Wait for login pop up to apper, then closing it. So we can access search bar and rest of HTML\n",
    "button1 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//button[@class=\\\"_2KpZ6l _2doB4z\\\"]')))\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc3230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding search bar with the help of CLASS name and passing \"Sunglasses\"\n",
    "search_bar = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, '_3704LK')))\n",
    "search_bar.send_keys('Mobiles')\n",
    "search_bar.send_keys(Keys.RETURN)  # Pressing enter key to proceed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0877c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to append data \n",
    "brand_names = []\n",
    "mobile_names = []\n",
    "mobile_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bfd09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Page ----------------------------------------------------------------------------------------\n",
    "brand_names_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_2WkVRV\\\"]')  # Finding brand names with relative XPATH\n",
    "for i in brand_names_element[0:100]:\n",
    "    text = i.text\n",
    "    brand_names.append(text)  # Appending brand names\n",
    "    \n",
    "    \n",
    "mobile_names_element = driver.find_elements(By.XPATH, '//a[@class=\\\"IRpwTa\\\"]')  # Finding glassess description with relative XPATH\n",
    "for i in mobile_names_element[0:100]:\n",
    "    text = i.text\n",
    "    mobile_names.append(text)  # Appending description\n",
    "    \n",
    "    \n",
    "price_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_30jeq3\\\"]')  # Finding price with relative XPATH\n",
    "for i in price_element[0:100]:\n",
    "    text = i.text\n",
    "    mobile_price.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269fcdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "next_page.click()  # Navigating to Second Page for next 40 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df906b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Page ----------------------------------------------------------------------------------------\n",
    "brand_names_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_2WkVRV\\\"]')   # Finding brand names with relative XPATH\n",
    "for i in brand_names_element[0:100]:\n",
    "    text = i.text\n",
    "    brand_names.append(text)\n",
    "    \n",
    "    \n",
    "mobile_names_element = driver.find_elements(By.XPATH, '//a[@class=\\\"IRpwTa\\\"]')  # Finding glassess description with relative XPATH\n",
    "for i in mobile_names_element[0:100]:\n",
    "    text = i.text\n",
    "    mobile_names.append(text)\n",
    "    \n",
    "    \n",
    "price_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_30jeq3\\\"]')  # Finding price with relative XPATH\n",
    "for i in price_element[0:100]:\n",
    "    text = i.text\n",
    "    mobile_price.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee49669",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "next_page.click()  # Navigating to Second Page for next 40 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Page ----------------------------------------------------------------------------------------\n",
    "brand_names_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_2WkVRV\\\"]')   # Finding brand names with relative XPATH\n",
    "for i in brand_names_element[0:100]:\n",
    "    text = i.text\n",
    "    brand_names.append(text)\n",
    "    \n",
    "    \n",
    "mobile_names_element = driver.find_elements(By.XPATH, '//a[@class=\\\"IRpwTa\\\"]')  # Finding glassess description with relative XPATH\n",
    "for i in mobile_names_element[0:100]:\n",
    "    text = i.text\n",
    "    mobile_names.append(text)\n",
    "    \n",
    "    \n",
    "price_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_30jeq3\\\"]')  # Finding price with relative XPATH\n",
    "for i in price_element[0:100]:\n",
    "    text = i.text\n",
    "    mobile_price.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b2d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data frame for saving/processing scrapped data\n",
    "df = pd.DataFrame()\n",
    "df['Brand'] = brand_names[:100]\n",
    "df['Mobile Name'] = mobile_names[:100]\n",
    "df[\"Price\"] = mobile_price[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52245ed7",
   "metadata": {},
   "source": [
    "# Q5 - Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fa105",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = selenium.webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\")\n",
    "driver.get('https://www.google.com/maps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(4)\n",
    "search_bar=driver.find_element_by_id(\"searchboxinput\")\n",
    "city_name=input(\"Enter the City Name: \")\n",
    "search_bar.send_keys(city_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ecde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_id(\"searchbox-searchbutton\")\n",
    "search_button.click()\n",
    "\n",
    "from  geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"jupyter\")\n",
    "\n",
    "location= geolocator.geocode(loc)\n",
    "print(\"latitude is :-\" ,location.latitude,\"\\nlongtitude is:-\" ,location.longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb16bd5",
   "metadata": {},
   "source": [
    "# Q8 Write a python program to scrape the details for all billionaires from www.forbes.com.\n",
    "Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120360b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\", chrome_options=options)\n",
    "driver.get('https://www.forbes.com/?sh=151ff3c12254')  # opening web address in chrome driver browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922db20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "button1 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@class=\"hamburger_svg__fs-icon hamburger_svg__fs-icon--hamburger\"]')))\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d29760",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "a = ActionChains(driver)\n",
    "m = driver.find_element(By.LINK_TEXT ,\"Billionaires\")\n",
    "a.move_to_element(m).perform()\n",
    "n = driver.find_element(By.LINK_TEXT, \"World's Billionaires\")\n",
    "a.move_to_element(n).click().perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7098826",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "button2 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[8]/div/button')))\n",
    "button2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []\n",
    "Name = []\n",
    "Net_worth = []\n",
    "Age = []\n",
    "Citizenship = []\n",
    "Source = []\n",
    "Industry = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73003ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ranks = driver.find_elements(By.XPATH, '//div[@class=\"rank\"]')\n",
    "for i in all_ranks:\n",
    "    text = i.text\n",
    "    Rank.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6816547",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = driver.find_elements(By.XPATH, '//div[@class=\"personName\"]')\n",
    "for i in all_names:\n",
    "    text = i.text\n",
    "    Name.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3753387",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Net_worth = driver.find_elements(By.XPATH, '//div[@class=\"netWorth\"]')\n",
    "for i in all_Net_worth:\n",
    "    text = i.text\n",
    "    Net_worth.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c7838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ages = driver.find_elements(By.CLASS_NAME, 'age')\n",
    "for i in all_ages:\n",
    "    text = i.text\n",
    "    Age.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4fbbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Citizenship = driver.find_elements(By.CLASS_NAME, 'countryOfCitizenship')\n",
    "for i in all_Citizenship:\n",
    "    text = i.text\n",
    "    Citizenship.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Source = driver.find_elements(By.XPATH, '//span[@class=\"source-text\"]')\n",
    "for i in all_Source:\n",
    "    text = i.text\n",
    "    Source.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ee8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_industry = driver.find_elements(By.CLASS_NAME, \"category\")\n",
    "for i in all_industry:\n",
    "    text = i.text\n",
    "    Industry.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Rank'] = Rank[:200]\n",
    "df['Name'] = Name[:200]\n",
    "df['Net_worth'] = Net_worth[:200]\n",
    "df['Age'] = Age[:200]\n",
    "df['Citizenship'] = Citizenship[:200]\n",
    "df['Source'] = Source[:200]\n",
    "df['Industry'] = Industry[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e91cf54",
   "metadata": {},
   "source": [
    "# Q10 - Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in “London” location. \n",
    "You have to scrape hostel name, distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms from price, facilities and property description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408adc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\", chrome_options=options)\n",
    "driver.get('https://www.hostelworld.com/')  # opening web address in chrome driver browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c3068",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=driver.find_element_by_xpath('//div[@class=\"card\"]//a[@title=\"London Hostels\"]')\n",
    "img.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "href=driver.find_element_by_xpath('//wds-button//a[@class=\"button-native sc-wds-button\"]')\n",
    "show=href.get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "distance=[]\n",
    "rating=[]\n",
    "total_review=[]\n",
    "overall_review=[]\n",
    "privates=[]\n",
    "dorms=[]\n",
    "\n",
    "for i in driver.find_elements_by_class_name(\"title title-6\"):\n",
    "    name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_class_name(\"description\"):\n",
    "    distance.append(i.text.split(\"-\")[1])\n",
    "    \n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"keyword\"]//span'):\n",
    "    overall_review.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"score orange big\"]'):\n",
    "    rating.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"reviews\"]'):\n",
    "    total_review.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath('/html/body/div[3]/div/div/div[1]/div[4]/div/div/div[2]/div[3]/a[1]/div[1]/div'):\n",
    "    if i.text is None:\n",
    "        privates.append('-')\n",
    "    else:\n",
    "        privates.append(i.text)\n",
    "        \n",
    "for i in driver.find_elements_by_xpath('/html/body/div[3]/div/div/div[1]/div[4]/div/div/div[2]/div[3]/a[1]/div[2]/div'):\n",
    "    if i.text is None:\n",
    "        dorms.append('-')\n",
    "    else:\n",
    "        dorms.append(i.text)\n",
    "        \n",
    "nxt=driver.find_element_by_xpath('//i[@class=\"core-icon icon-core-chevron-right\"]')\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce8415",
   "metadata": {},
   "source": [
    "# Q9 - Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\", chrome_options=options)\n",
    "driver.get('https://www.youtube.com/watch?v=VTVBmUp6uII')  # opening web address in chrome driver browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51849d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "for i in range(0,20): # Dynamic Page\n",
    "    html = driver.find_element_by_tag_name('html')\n",
    "    html.send_keys(Keys.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db869802",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "Comment_upvote = []\n",
    "time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = driver.find_elements(By.XPATH, '//span[@class=\"style-scope yt-formatted-string\"]')\n",
    "for i in all_comments:\n",
    "    text = i.text\n",
    "    comments.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a7262",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comment_upvotes = driver.find_elements(By.XPATH, '//div[@class=\"style-scope ytd-comment-action-buttons-renderer\"]')\n",
    "for i in Comment_upvote:\n",
    "    text = i.text\n",
    "    Comment_upvote.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bcc51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = driver.find_elements(By.XPATH, '//a[@class=\"yt-simple-endpoint style-scope yt-formatted-string\"]')\n",
    "for i in times:\n",
    "    text = i.text\n",
    "    time.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a3afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['comments'] = comments\n",
    "df['Comment_upvote'] = Comment_upvote\n",
    "df['time'] = time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d8c7ec",
   "metadata": {},
   "source": [
    "# Q6 - Write a program to scrap details of all the funding deals for second quarter (i.e Jan 21 – March 21) from trak.in.url='https://trak.in/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\", chrome_options=options)\n",
    "driver.get('https://trak.in/')  # opening web address in chrome driver browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "funding=driver.find_element_by_xpath('//a[@title=\"http://trak.in/india-startup-funding-investment-2015/\"]')\n",
    "funding.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=driver.find_elements(By.XPATH, '//tbody/tr/td[2]')\n",
    "stname=driver.find_elements(By.XPATH, '//tbody/tr/td[3]')\n",
    "ind=driver.find_elements(By.XPATH, '//tbody/tr/td[4]')\n",
    "sub=driver.find_elements(By.XPATH, '//tbody/tr/td[5]')\n",
    "city=driver.find_elements(By.XPATH, '//tbody/tr/td[6]')\n",
    "inv=driver.find_elements(By.XPATH, '//tbody/tr/td[7]')\n",
    "invt=driver.find_elements(By.XPATH, '//tbody/tr/td[8]')\n",
    "amount=driver.find_elements(By.XPATH, '//tbody/tr/td[9]')\n",
    "\n",
    "funding=[]\n",
    "for i in range(len(city)):\n",
    "    temp={'Date':date[i].text,'Startup Name':stname[i].text,'Industy':ind[i].text,\n",
    "          'Sub-vertical':sub[i].text, 'City':city[i].text,'Investor':inv[i].text,\n",
    "          'Investment type':invt[i].text,'Amount(USD)':amount[i].text}\n",
    "    \n",
    "    funding.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d58dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "funding=funding[5:29]\n",
    "\n",
    "df=pd.DataFrame(funding)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce36457",
   "metadata": {},
   "source": [
    "# Q7 - Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d158f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\", chrome_options=options)\n",
    "driver.get('https://www.digit.in')  # opening web address in chrome driver browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d83628",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('//div[@class=\"menu\"]/ul/li[3]/a').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91378222",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ele=driver.find_element_by_xpath('//div[@class=\"Listbrand\"]/ul/li[10]/a')\n",
    "    driver.execute_script(\"arguments[0].click();\", ele)\n",
    "except ElementClickInterceptedException as e:\n",
    "    src= driver.find_element_by_xpath('//div[@class=\"Listbrand\"]/ul/li[10]/a').get_attribute('src')\n",
    "    driver.get(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e04ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_url=[]\n",
    "url=driver.find_elements_by_xpath('//div[@class=\"TopNumbeHeading active sticky-footer\"]/a')\n",
    "for i in url:\n",
    "    product_url.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_status=[]\n",
    "official_website=[]\n",
    "name=[]\n",
    "os=[]\n",
    "screen=[]\n",
    "processor=[]\n",
    "memory=[]\n",
    "released=[]\n",
    "cost=[]\n",
    "\n",
    "for i in product_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(4)\n",
    "    for i in driver.find_elements(By.XPATH, '//div[@class=\"heading-wraper\"]/h1'):\n",
    "        name.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[3]/div[3]/div[3]/div/ul/li[1]/div/p[2]/strong'):\n",
    "        os.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[3]/div[3]/div[3]/div/ul/li[2]/div/p[2]/strong'):\n",
    "        screen.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[3]/div[3]/div[3]/div/ul/li[3]/div/p[2]/strong'):\n",
    "        processor.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[3]/div[3]/div[3]/div/ul/li[4]/div/p[2]/strong'):\n",
    "        memory.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH, '//strong[@class=\"red\"]'):\n",
    "        mark_status.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[3]/div[3]/div[1]/div[2]/strong'):\n",
    "        released.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[3]/div[3]/div[1]/div[3]/strong'):\n",
    "        official_website.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH, '/html/body/div[3]/div[2]/div[3]/div[3]/div[4]/div/h2/strong'):\n",
    "        cost.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5232ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaming_laptop=pd.DataFrame({'Name':name,'Operating System':os,'Display':display,'Processor':processor,\n",
    "                          'Memory':memory,'Market Status':market_status,'Release Date':release_date,\n",
    "                          'Official Website':official_website,'Price':price})\n",
    "gaming_laptop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
