{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc92aee",
   "metadata": {},
   "source": [
    "# Flip Robot Assignment 3 Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1936ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException , NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1f257d",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ab2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0401af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec4db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding \"Search Bar\" for designation with the help of class name and passing \"Data Analyst\" string as arguement  \n",
    "designation = driver.find_element(By.CLASS_NAME, \"suggestor-input \")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b726d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding \"Search Bar\" for location with the help of XPATH and passing \"Banglaore\" string as arguement  \n",
    "locations = driver.find_element(By.XPATH, '//*[@id=\"root\"]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "locations.send_keys('Banglaore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aedcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding \"Button\" for submitting user input, with the help of class name and passing clicking on it to search  \n",
    "search = driver.find_element(By.CLASS_NAME, 'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "603cbab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to append data in list\n",
    "job_title1 = []\n",
    "job_location1 = []\n",
    "company_name1 = []\n",
    "experiance_required1 = []\n",
    "\n",
    "# Getting title tags\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "# Looping through each tag to get job title, from web element and appending each element to job_title1\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title1.append(title)\n",
    "    \n",
    "# Getting location tags\n",
    "location_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "# Looping through each tag to get job location, from web element and appending each element to job_location1\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location1.append(location)\n",
    "    \n",
    "# Getting company name tags    \n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "# Looping through each tag to get company name, from web element and appending each element to company_name1\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name1.append(company)\n",
    "\n",
    "# Getting experiance required tags     \n",
    "experiance_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "# Looping through each tag to get experiance required, from web element and appending each element to experiance_required1\n",
    "for i in experiance_tags[0:10]:\n",
    "    experiance = i.text\n",
    "    experiance_required1.append(experiance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f20fbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Data Frame to export/process extracted information\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Creating columns, and assigning values from lists\n",
    "df[\"Title\"] = job_title1\n",
    "df[\"Job_location\"] = job_location1\n",
    "df[\"Company_Name\"] = company_name1\n",
    "df[\"Experiance Required\"] = experiance_required1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e1eefe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Roles For Data Analyst in Bangalore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experiance Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Mangaluru/Mangalore, Pune, Bangalore/Bengaluru...</td>\n",
       "      <td>Coresight Research, Inc.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jar</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Analyst (DA)/ Team Lead (TL) -...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Bangalo...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Call For Clinical Data Analyst - Hyd/Bangalore...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Bangalo...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                        Data Analyst - CRM Platform   \n",
       "4                                       Data Analyst   \n",
       "5  Hiring For Data Analyst (DA)/ Team Lead (TL) -...   \n",
       "6  Call For Clinical Data Analyst - Hyd/Bangalore...   \n",
       "7                Payroll Transformation Data Analyst   \n",
       "8                Payroll Transformation Data Analyst   \n",
       "9            Master Data Management Business Analyst   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                       Chennai, Bangalore/Bengaluru   \n",
       "1  Mangaluru/Mangalore, Pune, Bangalore/Bengaluru...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Kolkata, Hyderabad/Secunderabad, Pune, Bangalo...   \n",
       "6  Kolkata, Hyderabad/Secunderabad, Pune, Bangalo...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "               Company_Name Experiance Required  \n",
       "0                Latentview             3-6 Yrs  \n",
       "1  Coresight Research, Inc.             4-8 Yrs  \n",
       "2                    Varite             2-5 Yrs  \n",
       "3         Artech infosystem             1-6 Yrs  \n",
       "4                       Jar             0-4 Yrs  \n",
       "5                 Cognizant             3-8 Yrs  \n",
       "6                 Cognizant             6-9 Yrs  \n",
       "7         Arrow Electronics            5-10 Yrs  \n",
       "8         Arrow Electronics             3-7 Yrs  \n",
       "9                 Accenture             6-8 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Job Roles For Data Analyst in Bangalore\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb757d6",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93f17ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b145b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "843a7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding \"Search Bar\" for designation with the help of class name and passing \"Data Scientist\" string as arguement  \n",
    "designation = driver.find_element(By.CLASS_NAME, \"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3820b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding \"Search Bar\" for location with the help of XPATH and passing \"Banglaore\" string as arguement  \n",
    "locations = driver.find_element(By.XPATH, '//*[@id=\"root\"]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "locations.send_keys('Banglaore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1568fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding \"Button\" for submitting user input, with the help of class name and passing clicking on it to search  \n",
    "search = driver.find_element(By.CLASS_NAME, 'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f12910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to append data in list\n",
    "job_title2 = []\n",
    "job_location2 = []\n",
    "company_name2 = []\n",
    "experiance_required2 = []\n",
    "\n",
    "\n",
    "# Getting title tags\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "# Looping through each tag to get job title, from web element and appending each element to job_title2\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title2.append(title)\n",
    "    \n",
    "# Getting location tags    \n",
    "location_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "# Looping through each tag to get job location, from web element and appending each element to job_location2\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location2.append(location)\n",
    "    \n",
    "    \n",
    "# Getting company name tags    \n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "# Looping through each tag to get company name, from web element and appending each element to company_name2\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name2.append(company)\n",
    "    \n",
    "# Getting experiance required tags     \n",
    "experiance_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "# Looping through each tag to get experiance required, from web element and appending each element to experiance_required2\n",
    "for i in experiance_tags[0:10]:\n",
    "    experiance = i.text\n",
    "    experiance_required2.append(experiance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "476861f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Data Frame to export/process extracted information\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Creating columns, and assigning values from lists\n",
    "\n",
    "df[\"Title\"] = job_title2\n",
    "df[\"Job_location\"] = job_location2\n",
    "df[\"Company_Name\"] = company_name2\n",
    "df[\"Experiance Required\"] = experiance_required2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "759bdcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Job Roles For Data Scientist in Bangalore \u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experiance Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Mumbai, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi, Pune, Gurgaon/Gurugram, Bangalore/B...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>10-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Computer Vision</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7            Data Scientist: Artificial Intelligence   \n",
       "8                   Data Scientist - Computer Vision   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                        Job_location             Company_Name  \\\n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...                Accenture   \n",
       "1  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...                Accenture   \n",
       "2  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...                  Mphasis   \n",
       "3                  Mumbai, Pune, Bangalore/Bengaluru               CitiusTech   \n",
       "4  New Delhi, Pune, Gurgaon/Gurugram, Bangalore/B...            ZS Associates   \n",
       "5  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...            Tech Mahindra   \n",
       "6    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "7                                Bangalore/Bengaluru                      IBM   \n",
       "8                                Bangalore/Bengaluru                  Walmart   \n",
       "9                 Pune, Chennai, Bangalore/Bengaluru                    Wipro   \n",
       "\n",
       "  Experiance Required  \n",
       "0             2-4 Yrs  \n",
       "1             4-7 Yrs  \n",
       "2            9-14 Yrs  \n",
       "3             5-9 Yrs  \n",
       "4             5-8 Yrs  \n",
       "5           10-14 Yrs  \n",
       "6            5-10 Yrs  \n",
       "7             4-8 Yrs  \n",
       "8             3-7 Yrs  \n",
       "9            8-13 Yrs  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1m Job Roles For Data Scientist in Bangalore \\033[0;0m\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e7e10",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d41e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\")\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "# Finding \"Search Bar\" for designation with the help of class name and passing \"Data Scientist\" string as arguement  \n",
    "designation = driver.find_element(By.CLASS_NAME, \"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')\n",
    "\n",
    "# Finding \"Search Bar\" for location with the help of XPATH and passing \"Delhi/NCR\" string as arguement  \n",
    "locations = driver.find_element(By.XPATH, '//*[@id=\"root\"]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "locations.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d516922",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, 'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e080a5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Finding \"Button\" for submitting user input, with the help of class name and passing clicking on it to search  \n",
    "search_filter = driver.find_element(By.XPATH, '/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p')\n",
    "search_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "959b03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to append data in list\n",
    "job_title3 = []\n",
    "job_location3 = []\n",
    "company_name3 = []\n",
    "experiance_required3 = []\n",
    "\n",
    "# Getting title tags\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title fw500 ellipsis\"]')\n",
    "# Looping through each tag to get job title, from web element and appending each element to job_title3\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title3.append(title)\n",
    "    \n",
    "    \n",
    "# Getting location tags\n",
    "location_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "# Looping through each tag to get job location, from web element and appending each element to job_location3\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location3.append(location)\n",
    "    \n",
    "    \n",
    "# Getting company name tags    \n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "# Looping through each tag to get company name, from web element and appending each element to company_name3\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name3.append(company)\n",
    "    \n",
    "# Getting experiance required tags     \n",
    "experiance_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "# Looping through each tag to get experiance required, from web element and appending each element to experiance_required3\n",
    "for i in experiance_tags[0:10]:\n",
    "    experiance = i.text\n",
    "    experiance_required3.append(experiance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88ab871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Job Roles For Data Scientist in Bangalore \u001b[0;0m\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1m Job Roles For Data Scientist in Bangalore \\033[0;0m\")\n",
    "\n",
    "# Creating Data Frame to export/process extracted information\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Creating columns, and assigning values from lists\n",
    "df[\"Title\"] = job_title3\n",
    "df[\"Job_location\"] = job_location3\n",
    "df[\"Company_Name\"] = company_name3\n",
    "df[\"Experiance Required\"] = experiance_required3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36433d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experiance Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Module Lead - BIDW</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>upGrad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geospatial Data Engineer/Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Louis Dreyfus Commodities</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python Programming Language Data Science Pract...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Scientific Computing (Proactive SO)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CGI</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                                 Module Lead - BIDW   \n",
       "2                       Data Scientist/AIML Engineer   \n",
       "3                 Geospatial Data Engineer/Scientist   \n",
       "4  Python Programming Language Data Science Pract...   \n",
       "5                                     Data Scientist   \n",
       "6                Scientific Computing (Proactive SO)   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                    DigitalBCG GAMMA Data Scientist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                 Noida, Nagpur, Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                     New Delhi, Bangalore/Bengaluru   \n",
       "\n",
       "                Company_Name Experiance Required  \n",
       "0                  Accenture             2-4 Yrs  \n",
       "1                    Mphasis             5-8 Yrs  \n",
       "2                     upGrad             0-2 Yrs  \n",
       "3  Louis Dreyfus Commodities            5-10 Yrs  \n",
       "4                  Accenture             4-6 Yrs  \n",
       "5                GlobalLogic            8-10 Yrs  \n",
       "6                        CGI             3-7 Yrs  \n",
       "7                    Infosys             2-7 Yrs  \n",
       "8                    Infosys             2-7 Yrs  \n",
       "9    Boston Consulting Group             2-5 Yrs  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8975c1f",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation. You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9afc536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = webdriver.Chrome('C:/chrome_driver/chromedriver.exe')\n",
    "\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "\n",
    "# Accessing nav bar element with the help of XPATH, and clicking on it to access drop down list\n",
    "salary = driver.find_element(By.XPATH, '//*[@id=\"ambitionbox-header\"]/nav/ul/li[3]/span')\n",
    "salary.click()\n",
    "\n",
    "# Incase website takes more time load, giving time to load elements, to avoid no such element error \n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# Accessing \"Browse salaries\" href, with the help of LINK TEXT name space\n",
    "second_click = driver.find_element(By.LINK_TEXT, 'Browse salaries')\n",
    "second_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1c2d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing search bar with the help of XPATH and passing \"Data Scientist\" as an arguement\n",
    "search_text = driver.find_element(By.XPATH, '//input[@id=\"jobProfileSearchbox\"]')\n",
    "search_text.send_keys('Data Scientist')\n",
    "\n",
    "# Allowing web page to load\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# Clicking on search results\n",
    "search_text_click = driver.find_element(By.XPATH, '//*[@id=\"salaries\"]/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p')\n",
    "search_text_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f098f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all elements with Relative XPATH\n",
    "elements = driver.find_elements(By.XPATH, '//div[@class=\"result-row\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4786878c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating empty list to store companies information\n",
    "companies = []\n",
    "\n",
    "# looping through company names, and appending text to companies list\n",
    "for i in elements:\n",
    "    temp = i.find_elements(By.TAG_NAME, 'a')\n",
    "    for i in temp:\n",
    "        companies.append(i.text[:-22])  # Removing \"Data Scientist Salary\" from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc03b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiance = []  # Creating empty list to store experiance required information\n",
    "\n",
    "# looping through elements, and appending experiance required to list\n",
    "for i in elements:\n",
    "    temp = i.find_elements(By.CLASS_NAME, 'sbold-list-header')\n",
    "    for i in temp:\n",
    "        experiance.append(i.text)\n",
    "        \n",
    "totaL_salary_record = []  # salary based on no. of feedbacks\n",
    "final_experiance = []  # Actual salary\n",
    "\n",
    "# looping through elements, and appending salary and total records processed\n",
    "for i in range(0, len(experiance)):\n",
    "    a = experiance[i].split(' (')\n",
    "    final_experiance.append(a[0])\n",
    "    totaL_salary_record.append(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17e4767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding average salary\n",
    "avg_elements = driver.find_elements(By.XPATH, '//p[@class=\"averageCtc\"]')\n",
    "average_sal = []\n",
    "for i in avg_elements:\n",
    "    average_sal.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "437a8edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_elements = driver.find_elements(By.XPATH, '//div[@class=\"salary-values\"]')\n",
    "min_max = []\n",
    "for i in min_max_elements:\n",
    "    min_max.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab45581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store salaries\n",
    "mina = []  # For storing minimum salary\n",
    "maxa = []  # For storing maximum salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92cce957",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in min_max:\n",
    "    a = i.split('\\n')\n",
    "    # print(a)\n",
    "    mina.append(a[0])  # Appending minimum salary\n",
    "    maxa.append(a[1])  # Appending maximum salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7b54c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Companies</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Experiance</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Avg Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 24 salaries)</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 32.2L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 59 salaries)</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 19.8L</td>\n",
       "      <td>₹ 26.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 49 salaries)</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 35 salaries)</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 118 salaries)</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 15.5L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sigmoid Analytics</td>\n",
       "      <td>based on 10 salaries)</td>\n",
       "      <td>1 yr experience</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 70 salaries)</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 14.6L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>based on 11 salaries)</td>\n",
       "      <td>4 yrs experience</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>based on 10 salaries)</td>\n",
       "      <td>4 yrs experience</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>based on 14 salaries)</td>\n",
       "      <td>3 yrs experience</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Companies                  Salary          Experiance  \\\n",
       "0                     Walmart   based on 24 salaries)  3-4 yrs experience   \n",
       "1                    Ab Inbev   based on 59 salaries)  2-4 yrs experience   \n",
       "2                       Optum   based on 49 salaries)  2-4 yrs experience   \n",
       "3                          ZS   based on 35 salaries)  1-2 yrs experience   \n",
       "4           Fractal Analytics  based on 118 salaries)  2-4 yrs experience   \n",
       "5           Sigmoid Analytics   based on 10 salaries)     1 yr experience   \n",
       "6             Tiger Analytics   based on 70 salaries)  2-4 yrs experience   \n",
       "7  Legato Health Technologies   based on 11 salaries)    4 yrs experience   \n",
       "8                        HSBC   based on 10 salaries)    4 yrs experience   \n",
       "9                    Tredence   based on 14 salaries)    3 yrs experience   \n",
       "\n",
       "  Min Salary Avg Salary Max Salary  \n",
       "0    ₹ 25.0L    ₹ 32.2L    ₹ 45.0L  \n",
       "1    ₹ 15.0L    ₹ 19.8L    ₹ 26.0L  \n",
       "2    ₹ 11.0L    ₹ 16.4L    ₹ 22.6L  \n",
       "3    ₹ 11.0L    ₹ 15.9L    ₹ 22.0L  \n",
       "4     ₹ 9.0L    ₹ 15.5L    ₹ 23.0L  \n",
       "5    ₹ 12.7L    ₹ 14.7L    ₹ 19.7L  \n",
       "6     ₹ 9.0L    ₹ 14.6L    ₹ 20.0L  \n",
       "7    ₹ 11.0L    ₹ 14.5L    ₹ 20.0L  \n",
       "8    ₹ 12.0L    ₹ 14.0L    ₹ 18.0L  \n",
       "9     ₹ 8.8L    ₹ 13.9L    ₹ 17.5L  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame to store/process information scrapped from website\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Creating columns\n",
    "df['Companies'] = companies\n",
    "df[\"Salary\"] = totaL_salary_record\n",
    "df[\"Experiance\"] = final_experiance\n",
    "df[\"Min Salary\"] = mina\n",
    "df[\"Avg Salary\"] = average_sal\n",
    "df[\"Max Salary\"] = maxa\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b030368f",
   "metadata": {},
   "source": [
    "# Q7 - On Myntra, Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "Link - Go to the link - https://www.myntra.com/shoes. \n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58db4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = webdriver.Chrome('C:/chrome_driver/chromedriver.exe')\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fca780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding price element with the help of XPATH, and clicking check box \n",
    "price = driver.find_element(By.XPATH, '//*[@id=\"mountRoot\"]/div/div[1]/main/div/div[1]/section/div/div[5]/ul/li[2]')\n",
    "price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a076d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding color element with the help of XPATH, and clicking check box for black color\n",
    "color = driver.find_element(By.XPATH, '//*[@id=\"mountRoot\"]/div/div[1]/main/div/div[1]/section/div/div[6]/ul/li[1]')\n",
    "color.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fce849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e67a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "brands=driver.find_elements(By.CLASS_NAME, 'product-brand') # scraping brands name by class name='product-brand'\n",
    "for i in brands:\n",
    "    brand.append(i.text)  # appending the company/brand in Brand list\n",
    "#    \n",
    "desc=driver.find_elements(By.CLASS_NAME, 'product-product') # scraping description by class name = 'product-product'\n",
    "for i in desc:\n",
    "    description.append(i.text)  # appending the description in list\n",
    "#\n",
    "prices=driver.find_elements(By.XPATH, '//div[@class=\"product-price\"]') # scraping the price from the xpath\n",
    "for i in prices:\n",
    "    price.append(i.text)  # appending the price in price list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8c9a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to next page to access more web elements\n",
    "nxt_button=driver.find_element(By.XPATH, '//*[@id=\"desktopSearchResults\"]/div[2]/section/div[2]/ul/li[12]/a')#scraping the list of buttons from the page\n",
    "nxt_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df890ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "brands=driver.find_elements(By.CLASS_NAME, 'product-brand')  # scraping brands name by class name='product-brand'\n",
    "for i in brands:\n",
    "    brand.append(i.text) # appending the company/brand in Brand list\n",
    "#    \n",
    "desc=driver.find_elements(By.CLASS_NAME, 'product-product') # scraping description by class name = 'product-product'\n",
    "for i in desc:\n",
    "    description.append(i.text)  # appending the description in list\n",
    "#\n",
    "prices=driver.find_elements(By.XPATH, '//div[@class=\"product-price\"]') # scraping the price from the xpath\n",
    "for i in prices:\n",
    "    price.append(i.text)  # appending the price in price list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f0cd1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Brand'] = brand\n",
    "df['Description'] = description\n",
    "df['Price | Actual Price | Discount'] = price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c57c02df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price | Actual Price | Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men HOVR SonicSE Running Shoes</td>\n",
       "      <td>Rs. 8499Rs. 9999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men ChargedEscape 3 BL Running</td>\n",
       "      <td>Rs. 7199Rs. 8999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Unisex 3ZER0 IV Basketball</td>\n",
       "      <td>Rs. 7649Rs. 8999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men GO WALK - TERRA Shoes</td>\n",
       "      <td>Rs. 8499Rs. 9999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Fuse 2.0 Training Shoes</td>\n",
       "      <td>Rs. 6399Rs. 7999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Black Leather Loafers</td>\n",
       "      <td>Rs. 8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Solid Regular Boots</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Sports Shoes</td>\n",
       "      <td>Rs. 8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Textured Block Sandals</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "      <td>Rs. 6509Rs. 9299(30% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                     Description  \\\n",
       "0     UNDER ARMOUR  Men HOVR SonicSE Running Shoes   \n",
       "1     UNDER ARMOUR  Men ChargedEscape 3 BL Running   \n",
       "2     UNDER ARMOUR      Unisex 3ZER0 IV Basketball   \n",
       "3         Skechers       Men GO WALK - TERRA Shoes   \n",
       "4             Puma     Men Fuse 2.0 Training Shoes   \n",
       "..             ...                             ...   \n",
       "95       J.FONTINI       Men Black Leather Loafers   \n",
       "96            ALDO       Women Solid Regular Boots   \n",
       "97        Skechers                Men Sports Shoes   \n",
       "98            ALDO          Textured Block Sandals   \n",
       "99  Tommy Hilfiger            Men Leather Sneakers   \n",
       "\n",
       "   Price | Actual Price | Discount  \n",
       "0        Rs. 8499Rs. 9999(15% OFF)  \n",
       "1        Rs. 7199Rs. 8999(20% OFF)  \n",
       "2        Rs. 7649Rs. 8999(15% OFF)  \n",
       "3        Rs. 8499Rs. 9999(15% OFF)  \n",
       "4        Rs. 6399Rs. 7999(20% OFF)  \n",
       "..                             ...  \n",
       "95                        Rs. 8490  \n",
       "96                       Rs. 11999  \n",
       "97                        Rs. 8499  \n",
       "98                        Rs. 7999  \n",
       "99       Rs. 6509Rs. 9299(30% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85424c3",
   "metadata": {},
   "source": [
    "# Q8: On Amazon, scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "Link - Go to webpage https://www.amazon.in/.\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "955be696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = webdriver.Chrome('C:/chrome_driver/chromedriver.exe')\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45fcd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = driver.find_element(By.ID, \"twotabsearchtextbox\")  # Finding element with the help ID\n",
    "product.send_keys('Laptop')  # Passing \"Laptop\" as an search keyword\n",
    "product.send_keys(Keys.RETURN)  # Pressing enter to load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4040c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding \"i7 processor\" from Radio boxex and clicking it with the help of XPATH\n",
    "processor = driver.find_element(By.XPATH, '//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/span')\n",
    "processor.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8790db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty lists, so we can append required data in specific list\n",
    "title = []\n",
    "rating = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a415c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting laptop names\n",
    "laptop_name_element = driver.find_elements(By.XPATH, '//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "for laptop in laptop_name_element[:10]:  # Looping for first 10 lapotps\n",
    "    i = laptop.text\n",
    "    title.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c67b7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a ratings box\n",
    "ratings_box = driver.find_elements(By.XPATH, '//div[@class=\"a-row a-size-small\"]/span')\n",
    "for i in range(0, 20):  # With rating, we are extracting total ratings which is not required\n",
    "    ratings = ratings_box[i].get_attribute('aria-label')\n",
    "    # It works, so not touching it is good choice, in future update i will update, or i can pass pass, for future use\n",
    "    if len(ratings) > 10:\n",
    "        if len(rating) == 10:\n",
    "            break\n",
    "        else:\n",
    "            rating.append(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec2b25d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elements with price information and extracting prices\n",
    "price_element = driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "for _ in price_element[:10]:\n",
    "    i = _.text \n",
    "    price.append(i)  # Appending prices in lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21621727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>67,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>1,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>93,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>67,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...</td>\n",
       "      <td>2.9 out of 5 stars</td>\n",
       "      <td>1,09,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>21,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Rating  \\\n",
       "0  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.8 out of 5 stars   \n",
       "1  Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...  4.2 out of 5 stars   \n",
       "2  ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...  4.3 out of 5 stars   \n",
       "3  HP Pavilion x360 11th Gen Intel Core i7 14 inc...  4.2 out of 5 stars   \n",
       "4  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...  4.5 out of 5 stars   \n",
       "5  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.8 out of 5 stars   \n",
       "6  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  4.3 out of 5 stars   \n",
       "7  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...  4.2 out of 5 stars   \n",
       "8  Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...  2.9 out of 5 stars   \n",
       "9  (Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...  4.2 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0    67,990  \n",
       "1  1,00,000  \n",
       "2    93,290  \n",
       "3    80,990  \n",
       "4    79,990  \n",
       "5    67,990  \n",
       "6    77,990  \n",
       "7    86,990  \n",
       "8  1,09,990  \n",
       "9    21,999  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame to extract/process scrapped information\n",
    "df = pd.DataFrame()\n",
    "df['Title'] = title\n",
    "df['Rating'] = rating\n",
    "df['Price'] = price\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fcfdc2",
   "metadata": {},
   "source": [
    "# Q4 - Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "29354a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = selenium.webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\")\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "# Wait for login pop up to apper, then closing it. So we can access search bar and rest of HTML\n",
    "button1 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//button[@class=\\\"_2KpZ6l _2doB4z\\\"]')))\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36eb9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding search bar with the help of CLASS name and passing \"Sunglasses\"\n",
    "search_bar = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, '_3704LK')))\n",
    "search_bar.send_keys('sunglasses')\n",
    "search_bar.send_keys(Keys.RETURN)  # Pressing enter key to proceed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48013e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to append data \n",
    "brand_names = []\n",
    "goggle_names = []\n",
    "goggle_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2bb38ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Page ----------------------------------------------------------------------------------------\n",
    "brand_names_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_2WkVRV\\\"]')  # Finding brand names with relative XPATH\n",
    "for i in brand_names_element[0:100]:\n",
    "    text = i.text\n",
    "    brand_names.append(text)  # Appending brand names\n",
    "    \n",
    "    \n",
    "goggle_names_element = driver.find_elements(By.XPATH, '//a[@class=\\\"IRpwTa\\\"]')  # Finding glassess description with relative XPATH\n",
    "for i in goggle_names_element[0:100]:\n",
    "    text = i.text\n",
    "    goggle_names.append(text)  # Appending description\n",
    "    \n",
    "    \n",
    "price_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_30jeq3\\\"]')  # Finding price with relative XPATH\n",
    "for i in price_element[0:100]:\n",
    "    text = i.text\n",
    "    goggle_price.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba76d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "next_page.click()  # Navigating to Second Page for next 40 glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c28d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Page ----------------------------------------------------------------------------------------\n",
    "brand_names_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_2WkVRV\\\"]')   # Finding brand names with relative XPATH\n",
    "for i in brand_names_element[0:100]:\n",
    "    text = i.text\n",
    "    brand_names.append(text)\n",
    "    \n",
    "    \n",
    "goggle_names_element = driver.find_elements(By.XPATH, '//a[@class=\\\"IRpwTa\\\"]')  # Finding glassess description with relative XPATH\n",
    "for i in goggle_names_element[0:100]:\n",
    "    text = i.text\n",
    "    goggle_names.append(text)\n",
    "    \n",
    "    \n",
    "price_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_30jeq3\\\"]')  # Finding price with relative XPATH\n",
    "for i in price_element[0:100]:\n",
    "    text = i.text\n",
    "    goggle_price.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e22044dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span')\n",
    "next_page.click()  # Navigating to Third Page for next 40 glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fd0097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Page ----------------------------------------------------------------------------------------\n",
    "brand_names_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_2WkVRV\\\"]')\n",
    "for i in brand_names_element[0:100]:\n",
    "    text = i.text\n",
    "    brand_names.append(text)\n",
    "    \n",
    "    \n",
    "goggle_names_element = driver.find_elements(By.XPATH, '//a[@class=\\\"IRpwTa\\\"]')\n",
    "for i in goggle_names_element[0:100]:\n",
    "    text = i.text\n",
    "    goggle_names.append(text)\n",
    "    \n",
    "    \n",
    "price_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_30jeq3\\\"]')\n",
    "for i in price_element[0:100]:\n",
    "    text = i.text\n",
    "    goggle_price.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2805ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Goggle Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Round Sunglasses (48)</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (51)</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (53)</td>\n",
       "      <td>₹213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                        Goggle Name  \\\n",
       "0      ROZZETTA CRAFT              UV Protection Aviator Sunglasses (55)   \n",
       "1      ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...   \n",
       "2            Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3               NuVew              UV Protection Aviator Sunglasses (57)   \n",
       "4   SHAAH COLLECTIONS                UV Protection Round Sunglasses (54)   \n",
       "..                ...                                                ...   \n",
       "95      VINCENT CHASE    by Lenskart UV Protection Round Sunglasses (48)   \n",
       "96      VINCENT CHASE     Polarized, UV Protection Round Sunglasses (51)   \n",
       "97               IDEE              UV Protection Aviator Sunglasses (58)   \n",
       "98         PHENOMENAL         UV Protection Retro Square Sunglasses (53)   \n",
       "99          ROYAL SON  Polarized, UV Protection Retro Square Sunglass...   \n",
       "\n",
       "     Price  \n",
       "0     ₹649  \n",
       "1     ₹399  \n",
       "2     ₹799  \n",
       "3     ₹198  \n",
       "4     ₹179  \n",
       "..     ...  \n",
       "95    ₹949  \n",
       "96    ₹999  \n",
       "97  ₹1,899  \n",
       "98    ₹213  \n",
       "99    ₹486  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame for saving/processing scrapped data\n",
    "df = pd.DataFrame()\n",
    "df['Brand'] = brand_names[:100]\n",
    "df['Goggle Name'] = goggle_names[:100]\n",
    "df[\"Price\"] = goggle_price[:100]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77abea17",
   "metadata": {},
   "source": [
    "# Q6 - Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1eb913e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = selenium.webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\")\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.flipkart.com/')\n",
    "button1 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//button[@class=\\\"_2KpZ6l _2doB4z\\\"]')))\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e663725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching \"sneakers\" in web page\n",
    "search_bar = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, '_3704LK')))\n",
    "search_bar.send_keys('sneakers')\n",
    "search_bar.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee818bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_names = []\n",
    "sneakers_names = []\n",
    "sneakers_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "79fbd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Page -------------------------------------------------------------------------------------\n",
    "brand_names_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_2WkVRV\\\"]')\n",
    "for i in brand_names_element[0:100]:  # finding brand_names and appending in brand names\n",
    "    text = i.text\n",
    "    sneakers_names.append(text)\n",
    "    \n",
    "    \n",
    "sneakers_names_element = driver.find_elements(By.XPATH, '//a[@class=\\\"IRpwTa\\\"]')\n",
    "for i in sneakers_names_element[0:100]:  # finding sneakers_names and appending in sneaker names\n",
    "    text = i.text\n",
    "    sneakers_names.append(text)\n",
    "    \n",
    "    \n",
    "price_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_30jeq3\\\"]')\n",
    "for i in price_element[0:100]:  # finding price and appending in sneakers_price\n",
    "    text = i.text\n",
    "    sneakers_price.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "52ffd57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ebc934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Page -------------------------------------------------------------------------------------\n",
    "brand_names_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_2WkVRV\\\"]')\n",
    "for i in brand_names_element[0:100]:  # finding brand_names and appending in brand Names\n",
    "    text = i.text\n",
    "    brand_names.append(text)\n",
    "    \n",
    "    \n",
    "sneakers_names_element = driver.find_elements(By.XPATH, '//a[@class=\\\"IRpwTa\\\"]')  # finding sneakers_names and appending in sneaker names\n",
    "for i in sneakers_names_element[0:100]:  \n",
    "    text = i.text\n",
    "    sneakers_names.append(text)\n",
    "    \n",
    "    \n",
    "price_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_30jeq3\\\"]')\n",
    "for i in price_element[0:100]:  # finding price and appending in sneakers_price\n",
    "    text = i.text\n",
    "    sneakers_price.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77b01cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span')\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0fb9eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Page -------------------------------------------------------------------------------------\n",
    "brand_names_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_2WkVRV\\\"]')\n",
    "for i in brand_names_element[0:100]:  # finding brand_names and appending in brand Names\n",
    "    text = i.text\n",
    "    brand_names.append(text)\n",
    "    \n",
    "    \n",
    "sneakers_names_element = driver.find_elements(By.XPATH, '//a[@class=\\\"IRpwTa\\\"]')\n",
    "for i in sneakers_names_element[0:100]:  # finding sneakers_names and appending in sneaker names\n",
    "    text = i.text\n",
    "    sneakers_names.append(text)\n",
    "    \n",
    "    \n",
    "price_element = driver.find_elements(By.XPATH, '//div[@class=\\\"_30jeq3\\\"]')\n",
    "for i in price_element[0:100]:  # finding price and appending in sneakers_price\n",
    "    text = i.text\n",
    "    sneakers_price.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a950c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>₹470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>shoocity</td>\n",
       "      <td>Casual Sneakers White Shoes For Girls And Snea...</td>\n",
       "      <td>₹649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Men's White Faux Leather Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>LOUIS PHILIPPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹2,799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description   Price\n",
       "0           Layasa                                   Sneakers For Men    ₹497\n",
       "1         RapidBox                                   Sneakers For Men    ₹590\n",
       "2           BRUTON               Modern Trendy Shoes Sneakers For Men    ₹470\n",
       "3           Labbin                                   Sneakers For Men    ₹499\n",
       "4           BRUTON  Lightweight Pack Of 1 Trendy Sneakers Sneakers...    ₹259\n",
       "..             ...                                                ...     ...\n",
       "95        shoocity  Casual Sneakers White Shoes For Girls And Snea...    ₹649\n",
       "96      HIGHLANDER  Casual , Partywear Sneakers Shoes For Men's An...    ₹995\n",
       "97          Shozie          Men's White Faux Leather Sneakers For Men    ₹449\n",
       "98          BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men    ₹636\n",
       "99  LOUIS PHILIPPE                                   Sneakers For Men  ₹2,799\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame for saving/processing scrapped data\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Brand'] = brand_names[:100]\n",
    "df['Product Description'] = sneakers_names[:100]\n",
    "df[\"Price\"] = sneakers_price[:100]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a027b56",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b38da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Chrome Driver\n",
    "driver = selenium.webdriver.Chrome(\"C:/chrome_driver/chromedriver.exe\")\n",
    "\n",
    "# opening web address in chrome driver browser to access html, css information\n",
    "driver.get('https://www.flipkart.com/')\n",
    "button1 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//button[@class=\\\"_2KpZ6l _2doB4z\\\"]')))\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "545e36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding search bar with the help of Class name\n",
    "search_bar = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, '_3704LK')))\n",
    "search_bar.send_keys('iphone 11')  # giving iphone11 as arguement in search bar \n",
    "search_bar.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c24fda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening iphone 11 from results\n",
    "phone = WebDriverWait(driver, 3).until(EC.presence_of_element_located((By.XPATH, '//a[@class=\"_1fQZEK\"]')))\n",
    "a = phone.get_attribute('href') # opening in same address, as flipkart opens new tab when clicked on link \n",
    "driver.get(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa9b5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on all review to view all reviews for iphone 11\n",
    "all_review = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[9]/div[7]/div/a/div')\n",
    "all_review.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d787626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "rating = []\n",
    "review_title = []\n",
    "review_description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b606fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending page no. links in list to iterate over to get 100 results\n",
    "links = driver.find_elements(By.XPATH, '//a[@class=\"ge-49M\"]')\n",
    "link = []\n",
    "for _ in links:\n",
    "    link.append(_.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f142ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For first page, extracting review title\n",
    "review_title_element = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for _ in review_title_element:\n",
    "    a = _.text\n",
    "    review_title.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "174b9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For first page, extracting review description\n",
    "review_description_element = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for _ in review_description_element:\n",
    "    a = _.text\n",
    "    review_description.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6754b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For first page, extracting review rating\n",
    "ratings_element = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for _ in ratings_element:\n",
    "    a = _.text\n",
    "    rating.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "54c14631",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in link:\n",
    "    \n",
    "    driver.get(i)  # opening extracted href, i.e. moving to next page\n",
    "    driver.implicitly_wait(5)  # wait for some time to allow page to load\n",
    "    \n",
    "        \n",
    "    review_title_element = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')  # Extracting review title and appending\n",
    "    for _ in review_title_element:\n",
    "        a = _.text\n",
    "        review_title.append(a)\n",
    "        \n",
    "    review_description_element = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')  # Extracting review description and appending\n",
    "    for _ in review_description_element:\n",
    "        a = _.text\n",
    "        review_description.append(a)\n",
    "        \n",
    "    ratings_element = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')  # Extracting review rating and appending\n",
    "    for _ in ratings_element:\n",
    "        a = _.text\n",
    "        rating.append(a)\n",
    "        \n",
    "        \n",
    "    links = driver.find_elements(By.XPATH, '//a[@class=\"ge-49M\"]')  # Finding additional page no. links in bottom nav bar \n",
    "    \n",
    "    # Appending new links, checking if not present\n",
    "    for _ in links:  \n",
    "        linka = _.get_attribute('href')\n",
    "        if linka not in link:\n",
    "            link.append(_.get_attribute('href'))\n",
    "            \n",
    "        if len(link) == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "538e6db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It is better to buy iPhone 11 over iPhone 12 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A perfect phone and a good battery super camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>awesome Phone Smooth Touch Too good Sexyy look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>It was amazing experience for me. Honestly i a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I bought iPhone 11 On March 2021, And I am Wri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating           review_title  \\\n",
       "0       5         Simply awesome   \n",
       "1       4        Value-for-money   \n",
       "2       5       Perfect product!   \n",
       "3       5    Best in the market!   \n",
       "4       5      Worth every penny   \n",
       "..    ...                    ...   \n",
       "95      5      Worth every penny   \n",
       "96      5              Excellent   \n",
       "97      5  Mind-blowing purchase   \n",
       "98      4              Excellent   \n",
       "99      5               Terrific   \n",
       "\n",
       "                                   review_description  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   I'm Really happy with the product\\nDelivery wa...  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Great iPhone very snappy experience as apple k...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  It is better to buy iPhone 11 over iPhone 12 i...  \n",
       "96  A perfect phone and a good battery super camer...  \n",
       "97  awesome Phone Smooth Touch Too good Sexyy look...  \n",
       "98  It was amazing experience for me. Honestly i a...  \n",
       "99  I bought iPhone 11 On March 2021, And I am Wri...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame for saving/processing scrapped data\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['rating'] = rating[:100]\n",
    "df['review_title'] = review_title[:100]\n",
    "df['review_description'] = review_description[:100]\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
